tf.train.Optimizer.minimize(loss, global_step=None, 
var_list=None, gate_gradients=1, 
aggregation_method=None, colocate_gradients_with_ops=False, 
name=None, grad_loss=None)
添加操作节点，用于最小化loss，并更新var_list
该函数是简单的合并了compute_gradients()与apply_gradients()函数
返回为一个优化更新后的var_list，如果global_step非None，该操作还会为global_step做自增操作

tf.train.Optimizer.compute_gradients(loss,var_list=None, gate_gradients=1,
aggregation_method=None, 
colocate_gradients_with_ops=False, grad_loss=None)
对var_list中的变量计算loss的梯度
该函数为函数minimize()的第一部分，返回一个以元组(gradient, variable)组成的列表

tf.train.Optimizer.apply_gradients(grads_and_vars, global_step=None, name=None)
将计算出的梯度应用到变量上，是函数minimize()的第二部分，返回一个应用指定的梯度的操作Operation，对global_step做自增操作
